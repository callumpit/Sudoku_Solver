# Sudoku Solver
## Description of Algorithm
For my solution I have used a CSP Backtracking Search algorithm for solving sudoku puzzles. I decided to represent the state of the sudoku board as an object with all methods for minipulating the state and solving the board contained in its respective class. This includes methods for returning a list of the empty squares of the board, returning the domain of a specified square variable (reduced by its binary constraints), checking if the current state of the board is legitimate, checking if the current state of the board is solved, checking for empty domains of board variables, applying heuristics and applying constraint propagation. The class is initialised by the input board which is saved as an instance variable which all minipulation methods are performed on.

My sudoku_solver function takes a board state as a 9x9 numpy array and creates an instance of my SudokuState class, and then calls the Sudokustate.solve method. This algorithm first checks the input board to see if it is a valid initial state, i.e. does the initial state of the board break any of the rules of Sudoku. If it isn't valid the requested numpy array of 9x9 -1s is returned. If the initial state is valid, the method attempts to solve the board intially by constraint propagation by calling the SudokuState.proagate_constraints method. This method loops through all unassigned squares checking each ones
domain, restricted by its binary constraints. If its domain is single valued, the square is assigned to it. The loop is repeated untill there are no more squares with single valued domains.

The board is then checked if it is solved and returned if it is. If the board remains unsolved, the recursive SudokuState.backtrack method is called. The base case of this method checks if the board is solved and returns True if it is. If not the algorithm enters its main body. The method first gets a list of the empty squares on the board. Because all CSPs are commutative, it is not necessary to loop through all empty squares at this point so only one needs to be selected. The algorithm selects the most constrained variable (MCV) (applying the minimum remaining values heuristic), i.e. the one with the least values in its domain. In the case where more than one variable has the minimum domain size, the degree heuristic was used for tiebreaking by selecting the variable with the highest degree, i.e. the one involved in the largest number of constraints on other unassigned variables.

If the selected variable's domain is non-zero, each value in its domain is looped through. For each value in the domain, it is assigned to the value of the current square. A copy of the current state of the board is made case of failure further down the tree. The algorithm then calls the constraint propagation method to enforce all values implicit by the assignment of the current square to its current value. The algorithm then recursively calls the backtrack method. If this call results in failure, the board is reset and the current squares value is reset to zero. If the algorithm tries all values in the domain of the square it returns False as the current state of the board is unsolvable.

If the initial call of the backtracking algorithm results in failure it means that there is no possible solution for the board as every possible value of the first square cheked has resulted in failure, meaning that that square has no valid value. In this case the solve method returns the requested numpy array of 9x9 -1s.

## Optimisation of Backtracking Algorithm
I optimised my search algorithm by using heuristics for selecting variables and values and ensuring the methods used were as efficient as possible. The point of using the MRV heuristic was in order to prune the search tree by triggering failures earlier. Any variables in the input squares of the get_MRV method whose domain is empty gets checked first. The get_mrv method was further optimised by by ensuring that as soon as any variable with an empty domain was found it was returned in order to trigger a failure as soon as possible. It obviously doesn't matter which of the empty domain squares is selected as they all result in failure. The use of the degree heuristic in tiebreaking for the selection of the most restricted variable reduces the branching factor of the subsequent tree and resulted in a slight improvement in total runtime of the algorithm however its effect was far less than the MRV heuristic.

Initially I used forward checking to detect future failures inferred by variable assignments before the algorithm was called again recursively. However, I found that the algorithm performed slightly better by instead ensuring that, if a selected square wasn't arc consistent, the algorithm triggered a failure. 




